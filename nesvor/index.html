<!DOCTYPE html>
<html>

<head>
  <title>NeSVoR</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" type="text/css" href="../css/quasar.min.css" />
  <link rel="stylesheet" type="text/css" href="../css/pure-min.css" />
  <link rel="stylesheet" type="text/css" href="../css/spaces.css" />
  <link rel="stylesheet" type="text/css" href="../css/typo.css" />
  <link rel="stylesheet" type="text/css" href="../css/devices.min.css" />
  <link rel="stylesheet" type="text/css" href="../css/gh-fork-ribbon.css" />
  <link rel="stylesheet" type="text/css" href="../css/nord-dark.css" />
  <link rel="stylesheet" type="text/css" href="../css/nord-light.css" />
  <link rel="stylesheet" type="text/css" href="../css/font-nord.css" />
  <link rel="stylesheet" type="text/css" href="../css/bg-nord.css" />
  <link rel="stylesheet" type="text/css" href="../css/font-open-color.css" />
  <link rel="stylesheet" type="text/css" href="../css/bg-open-color.css" />
  <link rel="stylesheet" type="text/css" href="../css/material-icons.css" />
  <link rel="stylesheet" type="text/css" href="../css/abs-layout.css" />
  <link rel="stylesheet" type="text/css" href="../css/border-layout.css" />
  <link rel="stylesheet" type="text/css" href="../css/text-rect.css" />
  <link rel="stylesheet" type="text/css" href="../css/text-circle.css" />
  <link rel="stylesheet" type="text/css" href="../css/card.css" />
  <link rel="stylesheet" type="text/css" href="../css/lines.css" />
  <link rel="stylesheet" type="text/css" href="../css/filters.css" />
  <link rel="stylesheet" type="text/css" href="../fonts/remixicon.css" />
  <link rel="stylesheet" type="text/css" href="../css/style.css" />
</head>
<style>
  .small {
    font-size: 9pt;
  }

  .smallish {
    font-size: 12pt;
  }

  .tiny {
    font-size: 7pt;
  }

  .larger {
    font-size: 20pt;
  }

  .large {
    font-size: 24pt;
  }

  .footnote {
    position: absolute;
    bottom: 3em;
    font-size: 0.7em;
  }


  .split-70 .column:first-of-type {width: 70%; float:left}
  .split-70 .column:last-of-type {width: 30%; float:right}

  .split-40 .column:first-of-type {width: 40%; float:center}
  .split-40 .column:last-of-type {width: 60%; float:center}
</style>

<body>
  <textarea id="source">

    layout: true
    class: typo, typo-selection

    ---

    count: false
    class: center, middle

    # An introduction to<br /> implicit neural representations
    with a focus on NeSVoR<br /><br />

    .smallish[DL Journal Club<br /><br />
    
    
    Thomas Sanchez<br />
    UNIL - CHUV - CIBM ]

    ---
    # What are implicit neural representations (INRs)?

    * Modeling an image as a _continuous_ function of spatial coordinates.
    * Self-supervised learning (1 trained model per image)
    $$\begin{array}{ccc}
    \text{Classical deep learning} &\;\;\;\;\;\;\;\;\;\;\;\;& \text{Implicit neural models} \\\\
    \mathbf{f}\_{\theta}: \mathbf{x} \rightarrow \mathbf{y} && f_{\theta}:(x,y,z)\rightarrow (v,\sigma) \\\\
    \mathbf{x}, \mathbf{y} \in \mathbb{R}^N && x,y,z,v, \sigma \in\mathbb{R}
    \end{array}$$
    <br />
    .center[
    <img src="img/inr2.png" width="70%" /><br />
    ]

    .footnote[Mildenhall et al. (2020). NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis. *ECCV*]

    ---

    # A brief intro to Neural Radiance Fields (NeRFs)
    Ingredients: 1. INR &emsp; 2.Physical model &emsp; 3. Loss

    1 - $\text{NeRF} \subset \text{implicit neural models} \approx \text{coordinate-based models} $.
    $$f_{\theta}:(x,y,z)\rightarrow (v,\sigma)\;\;\; x,y,z,v, \sigma \in\mathbb{R}$$

    <p align="center" style="position: absolute; bottom: 2em; margin-left: -150px;">
    <img src="img/inr_full.png" width="70%" /><br />
    </p>
    .footnote[Mildenhall et al. (2020)]

    ???
    - INR: 
    - $\mathbf{r} = (x,y,z)$
    - Important bit: there is a physical model telling us what we will observe on our training data.

    ---

    # A brief intro to Neural Radiance Fields (NeRFs)
    Ingredients: 1. INR &emsp; 2.Physical model &emsp; 3. Loss

    2 - Physical model.
    $$V(\mathbf{r})=\int T(t) \sigma(\mathbf{r}(t)) v(\mathbf{r}(t), \mathbf{d}) dt\;\;\;\;\;\; \text{ } T(t)=\exp \left(-\int^t \sigma(\mathbf{r}(s)) d s\right)$$

    <p align="center" style="position: absolute; bottom: 2em; margin-left: -150px;">
    <img src="img/inr_full.png" width="70%" /><br />
    </p>
    .footnote[Mildenhall et al. (2020)]
    ???
    - INR: 
    - $\mathbf{r} = (x,y,z)$
    - Important bit: there is a physical model telling us what we will observe on our training data.

    ---

    # A brief intro to Neural Radiance Fields (NeRFs)
    Ingredients: 1. INR &emsp; 2.Physical model &emsp; 3. Loss

    3 - Loss. 
    $$\mathcal{L}=\sum_{\mathbf{r} \in \mathcal{R}}\|\hat{V}(\mathbf{r})-V(\mathbf{r})\|_2^2$$

    <p align="center" style="position: absolute; bottom: 2em; margin-left: -150px;">
      <img src="img/inr_full.png" width="70%" /><br />
    </p>
    
    .footnote[Mildenhall et al. (2020) ]
    ???
    - After discretization ...
    - Self-supervised approach.
    ---
    # The results are impressive
      Synthetic, physics-rendered dataset.
    <p align="center">
      <img src="img/nerf1.png" width="100%" /><br />
    </p>
    
    .footnote[Mildenhall et al. (2020) ]
    ---

    # The result is impressive
    Real-world data
    <p align="center">
      <img src="img/nerf2.png" width="100%" /><br />
    </p>
    
    .footnote[Mildenhall et al. (2020) ]

    ---
    # An important detail

    Positional encodings help learning high frequency details.$^{*,\dagger}$
    $$\gamma(p)=\left(\sin \left(2^{\circ} \pi p\right), \cos \left(2^{\circ} \pi p\right), \cdots, \sin \left(2^{L-1} \pi p\right), \cos \left(2^{L-1} \pi p\right)\right)$$
    
    <p align="center">
      <img src="img/fourier_features.png" width="60%" /><br />
    </p>

    .footnote[
      $^*$ N. Rahaman, et al. (2019). "On the spectral bias of neural networks." ICML<br />
      $^\dagger$ M. Tancik, et al. (2020). "Fourier features let networks learn high frequency functions in low dimensional domains." NeurIPS
      ]
    ---

    # What's the catch?
    Training a the vanilla NeRF is very slow!
    <br />
    <br />
    <p align="center">
      <img src="img/training_nerf.png" width="70%" /><br />
    </p>
    
    .footnote[Mildenhall et al. (2020) ]
    ---
    # NVIDIA gets involved ...
    Training goes down from *hours* to *seconds*.

    <p align="center">
      <img src="img/neural_hash.png" width="100%" /><br />
    </p>

    .footnote[T. Müller et al. (2022). Instant neural graphics primitives with a multiresolution hash encoding. ACM Transactions on Graphics (ToG), 41(4), 1-15.]
    
    ---

    count: false
    class: center, middle

    <p align="center">
      <img src="img/nesvor.png" width="90%" /><br />
    </p>
        
    ---

    # Fetal brain MRI: a quick refresher

    .column-2[
    *The problem of motion and low SNR*
    
    - Fast acquisition
      - Fast spin echo (FSE) sequences: 20-30 s ⇒ 1 slice in 1 s
      - Thick slices (resolution around 1x1x3mm3)
    - Orthogonal series (≥3) of 2D thick slices (3-5 mm)
    - Breath hold
    
    <p align="center">
      <img src="img/fetal_mri.gif" width="80%" /><br />
    </p>
    ]
    
    .footnote[Gholipour, Ali, et al. "Fetal MRI: a technical update with educational aspirations." Concepts in Magnetic Resonance Part A 43.6 (2014): 237-266.<br />
    Prayer, D., et al. "ISUOG Practice Guidelines: performance of fetal magnetic resonance imaging." Ultrasound in Obstetrics & Gynecology 49.5 (2017): 671-680.]
    ---
    class: split-70

    # Faster acquisition is not a silver bullet

    .column[
    *Remaining challenges:*
    <br />
    - Orthogonal acquired planes do not correspond to anatomical planes
    
    <br /><br />
    - Inter-slices and inter-stacks motion corruption
    
    <br /><br />
    - Inter-slice morphometry corrupted by motion and strong anisotropy

    ]
    .column[
    <p>
      <img src="img/fetal_brain3.gif" width="50%" /><br />
    </p>
    <p align="center">
      <img src="img/fetal_brain2.gif" width="50%" /><br />  
    </p>
    <p>
      <img src="img/fetal_brain1.png" width="50%" /><br />
    </p>
    ]

    ---
    # Super-resolution reconstruction
    Multiple motion corrupted acquisition $\to$ Single isotropic reconstructed volume

    <p align="center">
      <img src="img/srr.png" width="100%" />
    </p>

    ---
    class: split-70
    
    # NeSVoR in action
    Physical model.
    .column[
    $$I\_{i j}=C\_i B\_{i j} \sum\_{k=1}^{N\_v} M\_{i j k} V_k$$
    ]
    .column[
    - $I \in \mathbb{R}^{N\_s \times N\_p}$: Acquired data<br /> ($N\_s$: n. slices $N\_p$: n. pixels)
    - $I\_{ij}$: $i$-th pixel of $j$-th slice
    - $C\_i$: slice-wise scaling 
    - $B\_{i j}$: bias field
    - $M\_{i j k}$: motion coefficient
    - $V \in \mathbb{R}^{N\_v}$: 3D volume
    ]

    $$I\_{i j}=C\_i \int\_{\Omega} M\_{i j}(x) B\_i(x)\left[V(x)+\epsilon\_i(x)\right] \mathrm{d} x$$
  
    ---
    # References
    - [TUM AI Lecture Series - Neural Fields Beyond Novel View Synthesis (Andrea Tagliasacchi)](https://www.youtube.com/watch?v=nRCOsBHt97E)
    - Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., & Ng, R. (2020, August). NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I (pp. 405-421).
    - N. Rahaman, et al. (2019). "On the spectral bias of neural networks." ICML<br />
    - M. Tancik, et al. (2020). "Fourier features let networks learn high frequency functions in low dimensional domains." NeurIPS
    - Müller, T., Evans, A., Schied, C., & Keller, A. (2022). Instant neural graphics primitives with a multiresolution hash encoding. ACM Transactions on Graphics (ToG), 41(4), 1-15.
    - Xu, J., Moyer, D., Gagoski, B., Iglesias, J. E., Grant, P. E., Golland, P., & Adalsteinsson, E. (2023). NeSVoR: Implicit Neural Representation for Slice-to-Volume Reconstruction in MRI. IEEE Transactions on Medical Imaging.

    </textarea>

  <script src="http://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript"></script>
  <script type="text/javascript">
    var slideshow = remark.create({
      highlightStyle: 'monokai',
      highlightLanguage: 'remark',
      highlightLines: true,
      countIncrementalSlides: false,
      highlightSpans: true,
      ratio: '16:9'
    });
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
</body>

</html>